Алгоритмы классификации — просто и понятно
1. Алгоритм KNN (K-ближайших соседей)
Этот алгоритм решает, к какому классу принадлежит новая точка, глядя на ближайшие к ней точки.

Точки данных — это объекты с несколькими параметрами (например, цвет, размер и т. д.).
Пространство — если у каждой точки 3 параметра, то они существуют в 3-мерном пространстве. Если 4 параметра — в 4-мерном и так далее.
Выбор числа соседей (k):

Если k слишком маленькое (например, 1), результат может быть нестабильным.
Если k слишком большое, алгоритм может учитывать слишком много данных, что снизит точность.
Четное или нечетное k важно, чтобы избежать ничьей при голосовании соседей.
2. Метрики определения расстояния
Чтобы найти ближайшие точки, нужно измерить расстояние. Есть два популярных способа:

Манхэттенское расстояние — сумма разностей координат. Представьте, что вы идете по улицам города, двигаясь только вверх, вниз, влево и вправо.
Евклидово расстояние — обычное прямое расстояние между точками (как по линейке).
3. Алгоритмы ускорения поиска ближайших соседей
Так как сравнивать каждую точку со всеми другими медленно, используют оптимизированные структуры данных:

Алгоритм шарового дерева (Ball Tree) — группирует точки в сферические кластеры, что ускоряет поиск ближайших.
Алгоритм KD-дерева (KD-Tree) — разбивает пространство на области и позволяет быстро находить ближайших соседей.
Метод грубой силы — просто сравнивает каждую точку со всеми остальными (медленно, но просто).
Этот материал — основа работы алгоритма KNN.

import matplotlib.pyplot as plt
# Импортируем библиотеку для построения графиков

x = [4,5,10,4,3,11,14,8,10,12]
# Координаты x для точек данных

y = [21,19,24,17,16,25,24,22,21,21]
# Координаты y для точек данных

classes = [0,0,1,0,0,1,1,0,1,1]
# Метки классов (0 или 1) для каждой точки

plt.scatter(x, y, c=classes)
# Рисуем точки на графике, цвет зависит от класса

# plt.show()
# (Закомментировано) Можно включить, чтобы посмотреть точки перед классификацией

from sklearn.neighbors import KNeighborsClassifier
# Импортируем алгоритм K-ближайших соседей (KNN) из библиотеки sklearn

data = list(zip(x, y))
# Объединяем x и y в список пар координат

knn = KNeighborsClassifier(n_neighbors=5)
# Создаём модель KNN с 5 ближайшими соседями

knn.fit(data, classes)
# Обучаем модель на данных (координаты -> классы)

new_x = 8
new_y = 21
# Координаты новой точки, которую нужно классифицировать

new_point = [(new_x, new_y)]
# Записываем новую точку в виде списка кортежей (так требует sklearn)

prediction = knn.predict(new_point)
# Предсказываем класс новой точки

print(prediction)
# Выводим предсказанный класс

plt.scatter(x + [new_x], y + [new_y], c=classes + [prediction[0]])
# Рисуем график снова, включая новую точку, цвет зависит от предсказанного класса

plt.text(x=new_x - 1.7, y=new_y - 0.7, s=f"new point, class: {prediction[0]}")
# Подписываем новую точку на графике (сдвигаем текст немного влево и вниз)

plt.show()
# Показываем итоговый график с новой точкой

