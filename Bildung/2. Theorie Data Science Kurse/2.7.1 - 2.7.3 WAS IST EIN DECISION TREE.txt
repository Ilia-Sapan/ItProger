Конспект 2.7.1 – 2.7.3: Decision Trees
2.7.1. Что такое Decision Tree?
Decision Tree (дерево решений) – это алгоритм машинного обучения, используемый для классификации и регрессии. Визуально он представляет собой дерево, где каждый узел – это проверка условия (например, «Если температура выше 20°C?»), а листья – конечные классы.

Читается сверху вниз. Начинается с корневого узла, затем по условиям разделяется на подузлы.
В каждом узле задается бинарный вопрос, после которого данные делятся на две группы.
Используется в различных областях, например:
Финансы: определение кредитоспособности клиента.
Медицина: классификация заболеваний.
Бизнес: предсказание покупательского поведения.
2.7.2. Структура Decision Tree
Основа – разделение данных по определенным критериям.
Рассмотрим простой пример с координатами точек:
У нас есть точки синие и зеленые, разделенные вертикальной линией на x = 2.
Если x < 2 → синий, иначе → зеленый.
Это можно выразить через дерево решений.
Пример усложняется:

Добавляется третья категория – красные точки.
Теперь необходимо добавить еще одно разделение, например, по y.
Новое правило:
Если x < 2 и y > 2 → красный
Если x < 2 и y < 2 → синий
Если x ≥ 2 → зеленый
Так создается новый уровень дерева.
2.7.3. Обучение Decision Tree
Вопрос: Как алгоритм выбирает, какие вопросы задавать?

Критерий выбора признака – информационный выигрыш (Information Gain):

Рассчитывается на основе энтропии, измеряя, насколько чистыми (однородными) становятся подгруппы после разделения.
Чем выше информационный выигрыш, тем лучше разбиение.
Другие критерии:

Gain Ratio – учитывает размер групп после разделения.
Gini Impurity – используется в алгоритме CART, оценивает вероятность неправильной классификации.
Процесс обучения:

Определяем корневой узел (лучший признак для разделения).
Разделяем данные и строим поддеревья.
Повторяем процесс, пока:
Группа становится полностью однородной (энтропия ≈ 0).
Дерево не достигнет предела по глубине (для предотвращения переобучения).
Когда остановиться?

Если добавление новых узлов не улучшает точность.
Если достигнута максимальная глубина.
Итог: Decision Tree – мощный, но чувствительный к изменениям данных метод. Важно балансировать между глубиной дерева и обобщающей способностью (чтобы избежать переобучения).